<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Way</title>
    <link rel = "stylesheet" href = "./sty.css">
</head>
<body>
    <div class = "navbar">
        <img src="./Photos App Icon.jpg" alt="AIway" id = "image">
        <span id = "title">AI Way</span>
        <nav>
            <ul>
                <li><a href="./bo.html">Home</a></li>
                <li><a href="./about.html">About</a></li>
                <li><a href="./acc.html">Login</a></li>
            </ul>
        </nav>
    </div>
    <div id = "about">
        <h1 style="font-family: Georgia, 'Times New Roman', Times, serif; font-weight: 300; text-align: center; text-decoration: underline; ">ABOUT THE PROJECT</h1>
        <h2>1. QnA System using Pre-trained HuggingFace Transformer</h2>
        The QnA system relies on state-of-the-art pre-trained models provided by HuggingFace Transformers, such as BERT, GPT, and DistilBERT. These models have been fine-tuned on large datasets to understand the context of questions and provide accurate answers. The system preprocesses the input questions and documents, tokenizes them, and feeds them into the pre-trained model. Through attention mechanisms and contextual understanding, the model identifies relevant passages within the documents and extracts answers to the questions posed by the users. By leveraging transfer learning, the QnA system can adapt to various domains and provide accurate responses even with limited training data.
        The QnA system utilizes transformer-based architectures like BERT (Bidirectional Encoder Representations from Transformers) or DistilBERT. These models consist of multiple layers of attention mechanisms and feed-forward neural networks. BERT, for instance, has an encoder-decoder structure where the encoder processes the input text bidirectionally, capturing contextual information effectively. The attention mechanism in transformers enables the model to focus on relevant parts of the input during training and inference, facilitating accurate question answering.
        
        <h2>2. Topic Modelling using LDA</h2>
        Latent Dirichlet Allocation (LDA) is a probabilistic generative model used for topic modeling. In the context of your project, LDA is applied to analyze the contents of uploaded PDF documents and uncover latent topics within the text. The algorithm works by assuming that each document is a mixture of topics, and each word in the document is attributable to one of the document's topics. By iteratively assigning words to topics and documents to distributions of topics, LDA discovers the underlying thematic structure of the documents. This enables users to gain insights into the main themes and topics discussed in the documents, facilitating better understanding and information retrieval.
        Latent Dirichlet Allocation (LDA) is a generative probabilistic model composed of multiple components, including document-topic distributions and topic-word distributions. In LDA, each document is represented as a mixture of topics, and each topic is characterized by a distribution of words. The model infers the underlying topics by iteratively assigning words to topics based on statistical distributions. Through this process, LDA uncovers the latent thematic structure of the documents, providing valuable insights into the main topics discussed.
        
        <h2>3. Multimodal Part - OCR for Handwritten Content Detection using ResNet</h2>
        Optical Character Recognition (OCR) is a technology that enables the conversion of different types of documents, including handwritten text, into machine-readable text. The OCR component of your project utilizes ResNet, a deep convolutional neural network architecture, to perform character recognition on images containing handwritten content within PDF documents. ResNet has demonstrated remarkable performance in image recognition tasks by employing skip connections to mitigate the vanishing gradient problem. By extracting text from images, the system enhances its ability to process diverse types of content and make them accessible for further analysis and retrieval.
        ResNet (Residual Neural Network) is a deep convolutional neural network architecture characterized by residual connections. These connections enable the network to bypass certain layers, mitigating the vanishing gradient problem and facilitating the training of very deep networks. In your project, ResNet is employed to perform character recognition on images containing handwritten content within PDF documents. The architecture consists of multiple convolutional layers followed by pooling layers and fully connected layers, enabling it to effectively extract features and recognize characters from images.
        
        <h2>4. Cross-Language System with Goslate API</h2>
        Long Short-Term Memory (LSTM) networks are a type of recurrent neural network (RNN) architecture designed to capture long-term dependencies in sequential data. In your project, LSTM models are trained on the text extracted from the uploaded PDF documents to predict the next word in a sequence. By learning the contextual relationships between words and capturing patterns in the text data, LSTM models can generate accurate predictions about the next word that is likely to follow in a given context. This functionality enhances user experience by providing predictive text suggestions and facilitating smoother interaction with the document content.
        The Cross-Language System integrates the Goslate API, a powerful tool for language translation and detection. The system allows users to translate content seamlessly between different languages, facilitating cross-language information retrieval and accessibility. Goslate utilizes machine translation techniques to convert text from one language to another, enabling users to overcome language barriers and access information in their preferred language. Additionally, the system employs maximum likelihood principles and algorithms such as Langid, Textblob, and Langdetect to detect the language of the input text accurately. This ensures that the translation process is optimized for accuracy and reliability.
        The Cross-Language System integrates the Goslate API, which interacts with machine translation models to perform language translation tasks. The API may use neural machine translation models, such as those based on encoder-decoder architectures like sequence-to-sequence models. These models encode the input text into a fixed-size representation and decode it into the target language. Additionally, language detection algorithms like Langid, Textblob, and Langdetect analyze the linguistic features of the text to identify the language accurately.
        
        <h2>5. Next Word Prediction using LSTM</h2>
        Long Short-Term Memory (LSTM) networks consist of memory cells and gates that regulate the flow of information through the network over time. The architecture allows LSTMs to capture long-range dependencies in sequential data and mitigate the vanishing gradient problem commonly encountered in traditional RNNs. In your project, LSTM models are trained on the text extracted from PDF documents to predict the next word in a sequence. The models learn the contextual relationships between words and use this information to generate accurate predictions about the next word that is likely to occur based on the preceding words.
        
        These architectural details provide insights into how each model operates and contributes to the functionality of your CLIR project.
    </div>
    <div class="footer-content">
        <p>&copy; 2024 AI Way. All rights reserved.</p>
    </div>
</body>
</html>
